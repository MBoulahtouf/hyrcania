{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Fluorescence Spectroscopy Analysis for Olive Oil Aging\n",
    "\n",
    "This notebook demonstrates a complete, end-to-end workflow for analyzing fluorescence spectroscopy data from olive oil aging experiments using `RamanSPy`, `pandas`, `plotly`, and `scikit-learn`.\n",
    "\n",
    "### Workflow Overview:\n",
    "1.  **Mock Data Generation**: Create a realistic dataset if one doesn't exist.\n",
    "2.  **Data Loading**: Load multi-dimensional spectral data with robust metadata parsing.\n",
    "3.  **Preprocessing & Quality Control**: Apply a standard pipeline (denoising, baseline correction, normalization) and filter low-quality spectra.\n",
    "4.  **Advanced Visualization**: Generate a variety of plots, including 2D/3D interactive spectra, heatmaps, and aging progression dashboards.\n",
    "5.  **Statistical & Peak Analysis**: Extract key metrics (peak intensity, wavelength, SNR) and track how they evolve over time.\n",
    "6.  **Machine Learning**: Use PCA and a RandomForestClassifier to classify spectra based on their aging step.\n",
    "7.  **Data Export**: Save all processed data, statistical results, and high-resolution figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initial Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        </script>\n",
       "        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.0.1.min\"</script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and notebook configured.\n"
     ]
    }
   ],
   "source": [
    "# --- Core Libraries ---\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# --- RamanSPy ---\n",
    "import ramanspy as rp\n",
    "from ramanspy import SpectralContainer\n",
    "from ramanspy.preprocessing import Pipeline\n",
    "from ramanspy.preprocessing.denoise import SavGol\n",
    "from ramanspy.preprocessing.baseline import ASLS\n",
    "from ramanspy.preprocessing.normalise import Vector\n",
    "\n",
    "# --- Interactive Plotting ---\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode(connected=True)\n",
    "\n",
    "# --- Scientific & ML ---\n",
    "from scipy import signal\n",
    "from scipy.stats import norm, pearsonr\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- Setup & Configuration ---\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 7)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Libraries imported and notebook configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mock Data Generation (Optional)\n",
    "\n",
    "This section contains a utility function to generate mock data that mimics the expected structure. This makes the notebook fully runnable without needing the original dataset. If you have your data in the `data/extracted` directory, you can skip running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory 'data/extracted' already exists. Skipping generation.\n"
     ]
    }
   ],
   "source": [
    "def generate_mock_data(base_path=\"data/extracted\", aging_steps=5, spectra_per_file=3, files_per_step=4):\n",
    "    \"\"\"Generates mock fluorescence spectroscopy data.\n",
    "    \n",
    "    Creates a directory structure and CSV files with simulated spectral data.\n",
    "    The spectral peak shifts and broadens with each aging step.\n",
    "    \"\"\"\n",
    "    base_path = Path(base_path)\n",
    "    if base_path.exists():\n",
    "        print(f\"Data directory '{base_path}' already exists. Skipping generation.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Generating mock data in '{base_path}'...\")\n",
    "    wavelengths = np.linspace(400, 800, 1024) # Wavelengths in nm\n",
    "\n",
    "    for i in range(aging_steps):\n",
    "        step_dir = base_path / f\"AS{i}\" / \"Fluorescence\"\n",
    "        step_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for j in range(files_per_step):\n",
    "            # Simulate aging effect: peak shifts to longer wavelengths and broadens\n",
    "            peak_center = 450 + i * 15  # Peak center shifts right\n",
    "            peak_width = 25 + i * 5     # Peak gets broader\n",
    "            peak_height = 2000 - i * 150 # Intensity decreases\n",
    "\n",
    "            df = pd.DataFrame({'Wavelength_nm': wavelengths})\n",
    "            for k in range(spectra_per_file):\n",
    "                # Generate a spectrum using a normal distribution (Gaussian peak)\n",
    "                noise = np.random.normal(0, 50, len(wavelengths))\n",
    "                baseline = np.linspace(100, 50, len(wavelengths)) + np.random.rand() * 20\n",
    "                spectrum = peak_height * norm.pdf(wavelengths, peak_center + np.random.randn()*5, peak_width) + baseline + noise\n",
    "                df[f'Intensity_{k+1}'] = spectrum.astype(int)\n",
    "            \n",
    "            # Create a realistic filename\n",
    "            filename = f\"20250621_150{j}_AS{i}_Q1K2V{j}U{k}.csv\"\n",
    "            df.to_csv(step_dir / filename, index=False)\n",
    "            \n",
    "    print(\"Mock data generation complete.\")\n",
    "\n",
    "# Run the data generator\n",
    "generate_mock_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing Utilities\n",
    "\n",
    "Here, we define classes to handle loading, preprocessing, and quality control of the spectral data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyrcania.preprocessing import baseline_correction\n",
    "\n",
    "\n",
    "class FluorescenceDataLoader:\n",
    "    \"\"\"Advanced data loader for fluorescence spectroscopy data.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path=\"data/extracted\"):\n",
    "        self.data_path = Path(data_path)\n",
    "        if not self.data_path.exists():\n",
    "            raise FileNotFoundError(f\"Data path {self.data_path} not found. Please generate mock data or provide a valid path.\")\n",
    "        self.aging_steps = sorted([d for d in self.data_path.iterdir() if d.is_dir()])\n",
    "        self.encodings = ['utf-8', 'latin-1', 'cp1252']\n",
    "\n",
    "    def _load_csv_with_encoding(self, file_path):\n",
    "        \"\"\"Load CSV file with automatic encoding detection.\"\"\"\n",
    "        for encoding in self.encodings:\n",
    "            try:\n",
    "                return pd.read_csv(file_path, encoding=encoding)\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        raise ValueError(f\"Could not read {file_path} with any of the specified encodings.\")\n",
    "\n",
    "    def _extract_metadata_from_filename(self, filename):\n",
    "        \"\"\"Extract metadata from filename pattern (e.g., 20210512_0752_AS0_Q1K2V1U0.csv).\"\"\"\n",
    "        parts = Path(filename).stem.split('_')\n",
    "        return {'date': parts[0], 'time': parts[1], 'aging_step': parts[2], 'sample_code': parts[3]}\n",
    "\n",
    "    def load_aging_step_data(self, aging_step_path):\n",
    "        \"\"\"Load all fluorescence data for a single aging step into a list of dictionaries.\"\"\"\n",
    "        fluorescence_dir = aging_step_path / \"Fluorescence\"\n",
    "        files = sorted(fluorescence_dir.glob(\"*.csv\")) if fluorescence_dir.exists() else []\n",
    "        data_list = []\n",
    "        \n",
    "        for file_path in files:\n",
    "            try:\n",
    "                df = self._load_csv_with_encoding(file_path)\n",
    "                metadata = self._extract_metadata_from_filename(file_path.name)\n",
    "                \n",
    "                if len(df.columns) < 2:\n",
    "                    continue\n",
    "\n",
    "                wavelengths = df.iloc[:, 0].values\n",
    "                for i, col in enumerate(df.columns[1:]):\n",
    "                    intensities = df[col].values\n",
    "                    data_list.append({\n",
    "                        'wavelengths': wavelengths,\n",
    "                        'intensities': intensities,\n",
    "                        'metadata': {**metadata, 'spectrum_index': i, 'source_file': file_path.name}\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {e}\")\n",
    "        return data_list\n",
    "\n",
    "    def create_spectral_container(self, data_list):\n",
    "        \"\"\"Convert loaded data into a RamanSPy SpectralContainer.\"\"\"\n",
    "        if not data_list:\n",
    "            return None\n",
    "        \n",
    "        spectral_axis = data_list[0]['wavelengths']\n",
    "        # Stack all intensity arrays into a 2D numpy array (n_spectra, n_wavelengths)\n",
    "        intensities = np.vstack([d['intensities'] for d in data_list])\n",
    "        metadata_list = [d['metadata'] for d in data_list]\n",
    "        \n",
    "        return SpectralContainer(intensities, spectral_axis, metadata=metadata_list)\n",
    "\n",
    "class AdvancedPreprocessor:\n",
    "    \"\"\"A complete preprocessing pipeline for fluorescence data.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Define a robust preprocessing pipeline\n",
    "        self.pipeline = Pipeline([\n",
    "            ('savgol_denoise', SavGol(window_length=11, polyorder=3)),\n",
    "            ('asls_baseline', ASLS()),\n",
    "            ('vector_normalise', Vector())\n",
    "        ])\n",
    "\n",
    "    def apply_pipeline(self, spectral_container):\n",
    "        \"\"\"Apply the full preprocessing pipeline to a container.\"\"\"\n",
    "        return self.pipeline.apply(spectral_container)\n",
    "    \n",
    "    def quality_control(self, container, snr_threshold=3.0):\n",
    "        \"\"\"Filter spectra based on Signal-to-Noise Ratio (SNR).\"\"\"\n",
    "        snr_values = []\n",
    "        for spectrum in container:\n",
    "            # Use raw data for SNR calculation to avoid filtering out weak signals pre-correction\n",
    "            signal_power = np.mean(spectrum.spectral_data)\n",
    "            noise_power = np.std(spectrum.spectral_data)\n",
    "            snr = (signal_power / noise_power) if noise_power > 0 else 0\n",
    "            snr_values.append(snr)\n",
    "        \n",
    "        good_indices = [i for i, snr in enumerate(snr_values) if snr > snr_threshold]\n",
    "        print(f\"QC: Kept {len(good_indices)} of {len(container)} spectra (SNR threshold > {snr_threshold})\")\n",
    "        return container[good_indices], np.array(snr_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load, Preprocess, and Verify Data\n",
    "\n",
    "Now, we'll instantiate our helper classes and run the main data loading and preprocessing workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 aging steps. Loading...\n",
      "\n",
      "--- Processing Aging Step 0 ---\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    loader = FluorescenceDataLoader()\n",
    "    preprocessor = AdvancedPreprocessor()\n",
    "\n",
    "    aging_containers_raw = {}\n",
    "    aging_containers_processed = {}\n",
    "\n",
    "    print(f\"Found {len(loader.aging_steps)} aging steps. Loading...\")\n",
    "    # Load all aging steps, but you can slice for testing e.g., loader.aging_steps[:3]\n",
    "    for step_path in loader.aging_steps:\n",
    "        aging_label = step_path.name\n",
    "        print(f\"\\n--- Processing {aging_label} ---\")\n",
    "        \n",
    "        # Load raw data into list of dicts\n",
    "        raw_data_list = loader.load_aging_step_data(step_path)\n",
    "        if not raw_data_list:\n",
    "            print(f\"No data found for {aging_label}\")\n",
    "            continue\n",
    "\n",
    "        # Create a raw spectral container\n",
    "        container_raw = loader.create_spectral_container(raw_data_list)\n",
    "        aging_containers_raw[aging_label] = container_raw\n",
    "        print(f\"Loaded {len(container_raw)} raw spectra.\")\n",
    "\n",
    "        # Perform quality control\n",
    "        container_clean, snr_values = preprocessor.quality_control(container_raw, snr_threshold=5)\n",
    "        if len(container_clean) == 0:\n",
    "            print(f\"All spectra for {aging_label} were filtered out by QC.\")\n",
    "            continue\n",
    "\n",
    "        # Apply preprocessing pipeline\n",
    "        container_processed = preprocessor.apply_pipeline(container_clean)\n",
    "        aging_containers_processed[aging_label] = container_processed\n",
    "        print(f\"Successfully processed {len(container_processed)} spectra.\")\n",
    "\n",
    "    # Convert to lists for easier access\n",
    "    processed_containers = list(aging_containers_processed.values())\n",
    "    processed_labels = list(aging_containers_processed.keys())\n",
    "\n",
    "    print(f\"\\nWorkflow complete. Processed data for {len(processed_containers)} aging steps.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    processed_containers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Visualization\n",
    "This class encapsulates all plotting functions. **Correction Note:** Methods that generate Matplotlib plots now return the `figure` object. This allows us to either display the plot directly in the notebook (`plt.show()`) or save it to a file without showing it, fixing the bug in the original `DataExporter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedVisualizer:\n",
    "    \"\"\"Advanced visualization tools for fluorescence spectroscopy.\"\"\"\n",
    "    \n",
    "    def __init__(self, containers, labels):\n",
    "        self.containers = containers\n",
    "        self.labels = labels\n",
    "        self.colors = plt.cm.viridis(np.linspace(0, 1, len(labels)))\n",
    "    \n",
    "    def plot_spectrum_comparison(self, title=\"Spectrum Comparison\"):\n",
    "        \"\"\"Compare mean spectra of all aging steps with confidence intervals.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        for i, container in enumerate(self.containers):\n",
    "            mean_spec = container.mean.spectral_data\n",
    "            std_spec = np.std(container.spectral_data, axis=0)\n",
    "            ax.plot(container.spectral_axis, mean_spec, label=self.labels[i], color=self.colors[i], lw=2.5)\n",
    "            ax.fill_between(container.spectral_axis, mean_spec - std_spec, mean_spec + std_spec, \n",
    "                            color=self.colors[i], alpha=0.2)\n",
    "        \n",
    "        ax.set_title(title, fontsize=16, fontweight='bold')\n",
    "        ax.set_xlabel('Wavelength (nm)', fontsize=12)\n",
    "        ax.set_ylabel('Normalized Intensity (a.u.)', fontsize=12)\n",
    "        ax.legend()\n",
    "        ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def plot_heatmap(self, container_index=0, title_prefix=\"Spectral Heatmap\"):\n",
    "        \"\"\"Create a heatmap for a specific aging step.\"\"\"\n",
    "        container = self.containers[container_index]\n",
    "        label = self.labels[container_index]\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        im = ax.imshow(container.spectral_data, aspect='auto', cmap='viridis',\n",
    "                       extent=[container.spectral_axis[0], container.spectral_axis[-1], 0, len(container)])\n",
    "        \n",
    "        ax.set_title(f\"{title_prefix} - {label}\", fontsize=16, fontweight='bold')\n",
    "        ax.set_xlabel('Wavelength (nm)', fontsize=12)\n",
    "        ax.set_ylabel('Spectrum Index', fontsize=12)\n",
    "        \n",
    "        cbar = fig.colorbar(im, ax=ax)\n",
    "        cbar.set_label('Normalized Intensity')\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "        \n",
    "    def plot_interactive_3d_surface(self, container_index=0, title_prefix=\"Interactive 3D Surface\"):\n",
    "        \"\"\"Create an interactive 3D surface plot using Plotly.\"\"\"\n",
    "        container = self.containers[container_index]\n",
    "        label = self.labels[container_index]\n",
    "        \n",
    "        fig = go.Figure(data=[go.Surface(\n",
    "            z=container.spectral_data,\n",
    "            x=container.spectral_axis,\n",
    "            y=np.arange(len(container)),\n",
    "            colorscale='Viridis', cmin=container.spectral_data.min(), cmax=container.spectral_data.max(),\n",
    "            colorbar=dict(title='Intensity')\n",
    "        )])\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title={'text': f\"{title_prefix} - {label}\", 'y':0.9, 'x':0.5, 'xanchor': 'center', 'yanchor': 'top'},\n",
    "            scene=dict(\n",
    "                xaxis_title='Wavelength (nm)',\n",
    "                yaxis_title='Spectrum Index',\n",
    "                zaxis_title='Normalized Intensity'\n",
    "            ),\n",
    "            width=800, height=700\n",
    "        )\n",
    "        fig.show()\n",
    "        \n",
    "    def plot_pca_analysis(self):\n",
    "        \"\"\"Perform and visualize PCA on all combined data.\"\"\"\n",
    "        all_data = np.vstack([c.spectral_data for c in self.containers])\n",
    "        all_labels = []\n",
    "        for i, c in enumerate(self.containers):\n",
    "            all_labels.extend([self.labels[i]] * len(c))\n",
    "        \n",
    "        if all_data.shape[0] < 3:\n",
    "            print(\"PCA requires more data points.\")\n",
    "            return\n",
    "        \n",
    "        # Scale data before PCA\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(all_data)\n",
    "        \n",
    "        pca = PCA(n_components=3)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        \n",
    "        print(f\"Total explained variance by 3 PCs: {np.sum(pca.explained_variance_ratio_):.2%}\")\n",
    "\n",
    "        df_pca = pd.DataFrame(X_pca, columns=['PC1', 'PC2', 'PC3'])\n",
    "        df_pca['Aging Step'] = all_labels\n",
    "\n",
    "        fig = px.scatter_3d(\n",
    "            df_pca, x='PC1', y='PC2', z='PC3', \n",
    "            color='Aging Step', \n",
    "            title='PCA of Olive Oil Spectra Across Aging Steps',\n",
    "            labels={'PC1': f'PC1 ({pca.explained_variance_ratio_[0]:.1%})',\n",
    "                    'PC2': f'PC2 ({pca.explained_variance_ratio_[1]:.1%})',\n",
    "                    'PC3': f'PC3 ({pca.explained_variance_ratio_[2]:.1%})'}\n",
    "        )\n",
    "        fig.update_traces(marker=dict(size=5))\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Generating Visualizations\n",
    "\n",
    "Let's create the plots. Note that interactive plots (`plotly`) will be displayed directly, while static plots (`matplotlib`) will be shown via `plt.show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if processed_containers:\n",
    "    visualizer = AdvancedVisualizer(processed_containers, processed_labels)\n",
    "\n",
    "    # --- Static Plots (Matplotlib) ---\n",
    "    print(\"Generating static plots...\")\n",
    "    \n",
    "    # Plot 1: Mean Spectra Comparison\n",
    "    fig1 = visualizer.plot_spectrum_comparison(title=\"Mean Fluorescence Spectra Across Aging Steps\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 2: Heatmap of the first aging step\n",
    "    fig2 = visualizer.plot_heatmap(container_index=0)\n",
    "    plt.show()\n",
    "    \n",
    "    # --- Interactive Plots (Plotly) ---\n",
    "    print(\"\\nGenerating interactive plots...\")\n",
    "    \n",
    "    # Plot 3: Interactive 3D Surface\n",
    "    visualizer.plot_interactive_3d_surface(container_index=0)\n",
    "    \n",
    "    # Plot 4: Interactive PCA plot\n",
    "    visualizer.plot_pca_analysis()\n",
    "else:\n",
    "    print(\"Skipping visualization as no data was processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical and Peak Analysis\n",
    "\n",
    "These classes provide methods to extract quantitative metrics from the spectra and analyze how they change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatisticalAnalyzer:\n",
    "    \"\"\"Tools for extracting statistical metrics from spectral data.\"\"\"\n",
    "    \n",
    "    def _calculate_snr(self, data):\n",
    "        mean_spectrum = np.mean(data, axis=0)\n",
    "        signal = np.mean(mean_spectrum)\n",
    "        noise = np.std(mean_spectrum)\n",
    "        return signal / noise if noise > 0 else 0\n",
    "\n",
    "    def calculate_metrics(self, container):\n",
    "        \"\"\"Calculate a dictionary of key metrics for a container.\"\"\"\n",
    "        mean_spec = container.mean.spectral_data\n",
    "        \n",
    "        metrics = {\n",
    "            'mean_snr': self._calculate_snr(container.spectral_data),\n",
    "            'peak_intensity': np.max(mean_spec),\n",
    "            'peak_wavelength': container.spectral_axis[np.argmax(mean_spec)],\n",
    "            'total_intensity': np.mean(np.sum(container.spectral_data, axis=1))\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    def analyze_all_steps(self, containers, labels):\n",
    "        \"\"\"Analyze all aging steps and return a DataFrame of metrics.\"\"\"\n",
    "        all_metrics = []\n",
    "        for i, container in enumerate(containers):\n",
    "            metrics = self.calculate_metrics(container)\n",
    "            metrics['aging_step'] = labels[i]\n",
    "            all_metrics.append(metrics)\n",
    "        \n",
    "        return pd.DataFrame(all_metrics).set_index('aging_step')\n",
    "\n",
    "class PeakAnalyzer:\n",
    "    \"\"\"Advanced peak analysis for fluorescence spectra.\"\"\"\n",
    "\n",
    "    def find_peaks(self, spectrum, wavelengths, height=0.1, distance=10):\n",
    "        \"\"\"Find peaks in a single spectrum using scipy.signal.find_peaks.\"\"\"\n",
    "        peaks, properties = signal.find_peaks(spectrum, height=height, distance=distance)\n",
    "        return pd.DataFrame({\n",
    "            'wavelength': wavelengths[peaks],\n",
    "            'intensity': spectrum[peaks],\n",
    "            'prominence': properties.get('prominences', [None]*len(peaks))\n",
    "        })\n",
    "\n",
    "    def analyze_peak_evolution(self, containers, labels):\n",
    "        \"\"\"Analyze how the main peak evolves across all aging steps.\"\"\"\n",
    "        peak_info = []\n",
    "        for i, container in enumerate(containers):\n",
    "            mean_spec = container.mean.spectral_data\n",
    "            # Find the single most prominent peak in the mean spectrum\n",
    "            peaks_df = self.find_peaks(mean_spec, container.spectral_axis)\n",
    "            if not peaks_df.empty:\n",
    "                main_peak = peaks_df.loc[peaks_df['intensity'].idxmax()]\n",
    "                info = main_peak.to_dict()\n",
    "                info['aging_step'] = labels[i]\n",
    "                peak_info.append(info)\n",
    "        \n",
    "        return pd.DataFrame(peak_info).set_index('aging_step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Running Analysis and Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if processed_containers:\n",
    "    # Perform statistical and peak analysis\n",
    "    stat_analyzer = StatisticalAnalyzer()\n",
    "    stat_results_df = stat_analyzer.analyze_all_steps(processed_containers, processed_labels)\n",
    "    \n",
    "    peak_analyzer = PeakAnalyzer()\n",
    "    peak_results_df = peak_analyzer.analyze_peak_evolution(processed_containers, processed_labels)\n",
    "    \n",
    "    # Combine results for display\n",
    "    results_df = pd.concat([stat_results_df, peak_results_df.drop(columns=['intensity'])], axis=1)\n",
    "    results_df.rename(columns={'wavelength': 'main_peak_wavelength'}, inplace=True)\n",
    "\n",
    "    print(\"--- Combined Statistical and Peak Analysis Results ---\")\n",
    "    display(results_df)\n",
    "\n",
    "    # Visualize the results\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Evolution of Spectral Metrics Over Aging Steps', fontsize=18, fontweight='bold')\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    results_df['peak_intensity'].plot(ax=axes[0], style='o-', title='Peak Intensity', colormap='viridis', lw=2)\n",
    "    results_df['main_peak_wavelength'].plot(ax=axes[1], style='o-', title='Peak Wavelength', colormap='plasma', lw=2)\n",
    "    results_df['total_intensity'].plot(ax=axes[2], style='s-', title='Average Total Intensity', colormap='magma', lw=2)\n",
    "    results_df['prominence'].plot(ax=axes[3], style='^-', title='Main Peak Prominence', colormap='cividis', lw=2)\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_xlabel('Aging Step')\n",
    "        ax.grid(True, linestyle='--')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping statistical analysis as no data was processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Machine Learning Integration\n",
    "\n",
    "Here we attempt to build a classifier that can distinguish between different aging steps based purely on the spectral data. This demonstrates the potential for automated quality assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLIntegrator:\n",
    "    \"\"\"Machine learning integration for spectral classification.\"\"\"\n",
    "\n",
    "    def __init__(self, containers, labels):\n",
    "        self.containers = containers\n",
    "        self.labels = labels\n",
    "        self.scaler = StandardScaler()\n",
    "        # Use PCA to reduce dimensionality while keeping 95% of variance\n",
    "        self.pca = PCA(n_components=0.95)\n",
    "        self.model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare feature matrix (X) and target vector (y).\"\"\"\n",
    "        X = np.vstack([c.spectral_data for c in self.containers])\n",
    "        y = []\n",
    "        for i, c in enumerate(self.containers):\n",
    "            y.extend([self.labels[i]] * len(c))\n",
    "        return X, np.array(y)\n",
    "\n",
    "    def run_classification_pipeline(self):\n",
    "        \"\"\"Run the full train-test-evaluate pipeline.\"\"\"\n",
    "        X, y = self.prepare_data()\n",
    "        \n",
    "        # Split data, stratifying to handle imbalanced classes\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Fit scaler on training data only\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "\n",
    "        # Fit PCA on training data only\n",
    "        X_train_pca = self.pca.fit_transform(X_train_scaled)\n",
    "        X_test_pca = self.pca.transform(X_test_scaled)\n",
    "\n",
    "        print(f\"Original feature count: {X.shape[1]}\")\n",
    "        print(f\"PCA feature count: {self.pca.n_components_} (retaining {self.pca.explained_variance_ratio_.sum():.2%} variance)\")\n",
    "        \n",
    "        # Train model\n",
    "        self.model.fit(X_train_pca, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = self.model.predict(X_test_pca)\n",
    "        \n",
    "        print(\"\\n--- Classification Report ---\")\n",
    "        report = classification_report(y_test, y_pred, target_names=np.unique(y))\n",
    "        print(report)\n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if processed_containers and len(processed_containers) > 1:\n",
    "    ml_integrator = MLIntegrator(processed_containers, processed_labels)\n",
    "    classification_report_str = ml_integrator.run_classification_pipeline()\n",
    "else:\n",
    "    print(\"Skipping ML integration: requires at least 2 processed aging steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export and Save Results\n",
    "This class handles saving the processed data, statistical analysis, and visualizations to an `output` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExporter:\n",
    "    \"\"\"Export processed data, stats, and visualizations.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir=\"output\"):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        print(f\"Results will be saved to '{self.output_dir}'\")\n",
    "\n",
    "    def save_processed_data(self, containers, labels):\n",
    "        \"\"\"Save processed spectral data to separate CSV files.\"\"\"\n",
    "        data_dir = self.output_dir / \"processed_data\"\n",
    "        data_dir.mkdir(exist_ok=True)\n",
    "        for container, label in zip(containers, labels):\n",
    "            df = pd.DataFrame(container.spectral_data, columns=container.spectral_axis.astype(str))\n",
    "            filepath = data_dir / f\"processed_spectra_{label}.csv\"\n",
    "            df.to_csv(filepath, index_label='Spectrum_Index')\n",
    "        print(f\"Saved processed spectral data to '{data_dir}'.\")\n",
    "\n",
    "    def save_statistics(self, stats_df):\n",
    "        \"\"\"Save the statistical summary DataFrame to a CSV.\"\"\"\n",
    "        filepath = self.output_dir / \"statistical_summary.csv\"\n",
    "        stats_df.to_csv(filepath)\n",
    "        print(f\"Saved statistical summary to '{filepath}'.\")\n",
    "\n",
    "    def save_visualizations(self, visualizer_instance):\n",
    "        \"\"\"Save key Matplotlib visualizations as high-resolution images.\"\"\"\n",
    "        vis_dir = self.output_dir / \"visualizations\"\n",
    "        vis_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save Spectrum Comparison Plot\n",
    "        fig_comp = visualizer_instance.plot_spectrum_comparison()\n",
    "        fig_comp.savefig(vis_dir / \"spectrum_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig_comp) # Close figure to free memory\n",
    "\n",
    "        # Save Heatmap of first step\n",
    "        fig_heat = visualizer_instance.plot_heatmap(container_index=0)\n",
    "        fig_heat.savefig(vis_dir / \"heatmap_first_step.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig_heat)\n",
    "        \n",
    "        print(f\"Saved visualizations to '{vis_dir}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if processed_containers:\n",
    "    exporter = DataExporter()\n",
    "    \n",
    "    # Export processed spectra\n",
    "    exporter.save_processed_data(processed_containers, processed_labels)\n",
    "    \n",
    "    # Export statistical results\n",
    "    if 'results_df' in locals():\n",
    "        exporter.save_statistics(results_df)\n",
    "    \n",
    "    # Export visualizations\n",
    "    if 'visualizer' in locals():\n",
    "        exporter.save_visualizations(visualizer)\n",
    "        \n",
    "    print(\"\\n--- Export complete! ---\")\n",
    "else:\n",
    "    print(\"Skipping export as no data was processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Conclusions\n",
    "\n",
    "This notebook successfully executed a full analysis pipeline. Key findings often show a shift in peak wavelength and a change in spectral shape as the olive oil ages, which is quantifiable through statistical analysis and classifiable by machine learning models. The generated outputs in the `output` directory provide a comprehensive record of this analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hyrcania (Poetry)",
   "language": "python",
   "name": "hyrcania"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
